# Database Optimization Environment Configuration
# Copy these optimized settings to your .env files for each service
# Generated by Database Optimization Team - 2024

# ===========================================
# ANALYTICS SERVICE CONFIGURATION
# High read load from analytics queries
# ===========================================
# Analytics Service .env additions:
DB_POOL_MAX=50
DB_POOL_MIN=10
DB_IDLE_TIMEOUT=60000
DB_CONNECTION_TIMEOUT=15000
DB_STATEMENT_TIMEOUT=30000
DB_QUERY_TIMEOUT=25000

# ===========================================
# USER SERVICE CONFIGURATION  
# Moderate read/write load
# ===========================================
# User Service .env additions:
DB_POOL_MAX=30
DB_POOL_MIN=5
DB_IDLE_TIMEOUT=45000
DB_CONNECTION_TIMEOUT=12000
DB_STATEMENT_TIMEOUT=20000
DB_QUERY_TIMEOUT=15000

# ===========================================
# QR SERVICE CONFIGURATION
# High write load for QR code operations
# ===========================================
# QR Service .env additions:
DB_POOL_MAX=40
DB_POOL_MIN=8
DB_IDLE_TIMEOUT=45000
DB_CONNECTION_TIMEOUT=12000
DB_STATEMENT_TIMEOUT=20000
DB_QUERY_TIMEOUT=15000

# ===========================================
# OTHER SERVICES CONFIGURATION
# Standard load (file-service, notification-service, etc.)
# ===========================================
# Other Services .env additions:
DB_POOL_MAX=25
DB_POOL_MIN=3
DB_IDLE_TIMEOUT=45000
DB_CONNECTION_TIMEOUT=12000
DB_STATEMENT_TIMEOUT=20000
DB_QUERY_TIMEOUT=15000

# ===========================================
# POSTGRESQL SERVER CONFIGURATION
# Add these to your postgresql.conf
# ===========================================

# Connection Settings
# max_connections = 400                    # Total across all services ~300, reserve 100
# superuser_reserved_connections = 10

# Memory Settings (adjust based on available RAM)
# shared_buffers = 2GB                     # 25% of RAM (for 8GB+ systems)
# work_mem = 16MB                          # Increased for analytics queries
# maintenance_work_mem = 512MB             # For index maintenance
# effective_cache_size = 6GB               # 75% of RAM

# Query Performance (SSD optimized)
# random_page_cost = 1.1
# effective_io_concurrency = 200
# seq_page_cost = 1.0

# Timeouts and Locks
# statement_timeout = 30000               # 30 seconds
# lock_timeout = 10000                    # 10 seconds
# idle_in_transaction_session_timeout = 60000  # 60 seconds

# Performance Monitoring
# log_min_duration_statement = 1000      # Log slow queries (>1s)
# log_checkpoints = on
# log_lock_waits = on

# Parallel Query Processing
# max_parallel_workers_per_gather = 4
# max_parallel_workers = 8
# jit = on

# Background Writer
# bgwriter_delay = 200ms
# bgwriter_lru_maxpages = 100
# bgwriter_lru_multiplier = 2.0

# WAL Configuration
# wal_buffers = 32MB
# checkpoint_completion_target = 0.9
# checkpoint_timeout = 15min
# max_wal_size = 4GB
# min_wal_size = 1GB

# ===========================================
# DOCKER COMPOSE ENVIRONMENT VARIABLES
# Add these to your docker-compose.yml environment section
# ===========================================

# For analytics service:
services:
  analytics-service:
    environment:
      - DB_POOL_MAX=50
      - DB_POOL_MIN=10
      - DB_IDLE_TIMEOUT=60000
      - DB_CONNECTION_TIMEOUT=15000
      - DB_STATEMENT_TIMEOUT=30000
      - DB_QUERY_TIMEOUT=25000

# For user service:
  user-service:
    environment:
      - DB_POOL_MAX=30
      - DB_POOL_MIN=5
      - DB_IDLE_TIMEOUT=45000
      - DB_CONNECTION_TIMEOUT=12000
      - DB_STATEMENT_TIMEOUT=20000
      - DB_QUERY_TIMEOUT=15000

# For qr service:
  qr-service:
    environment:
      - DB_POOL_MAX=40
      - DB_POOL_MIN=8
      - DB_IDLE_TIMEOUT=45000
      - DB_CONNECTION_TIMEOUT=12000
      - DB_STATEMENT_TIMEOUT=20000
      - DB_QUERY_TIMEOUT=15000

# ===========================================
# MONITORING QUERIES
# Use these queries to monitor optimization effectiveness
# ===========================================

# Check connection pool health:
# SELECT * FROM connection_pool_metrics;

# Monitor index usage:
# SELECT * FROM analytics_index_usage WHERE usage_category != 'UNUSED';

# Get optimization alerts:
# SELECT * FROM check_connection_pool_health() WHERE alert_level != 'OK';

# View slow queries (if pg_stat_statements enabled):
# SELECT query, calls, total_exec_time, mean_exec_time 
# FROM pg_stat_statements 
# WHERE mean_exec_time > 1000 
# ORDER BY total_exec_time DESC;

# ===========================================
# DEPLOYMENT CHECKLIST
# ===========================================

# □ 1. Apply database migrations:
#      ./database/run_optimization_migrations.sh

# □ 2. Update PostgreSQL configuration (postgresql.conf):
#      - Increase max_connections to 400
#      - Set memory parameters based on available RAM
#      - Configure performance settings

# □ 3. Update service environment variables:
#      - Copy service-specific settings above
#      - Restart services after configuration changes

# □ 4. Enable monitoring:
#      - Set up alerts for connection pool utilization
#      - Monitor slow query logs
#      - Track index usage statistics

# □ 5. Gradual rollout:
#      - Deploy to staging first
#      - Monitor for 24 hours before production
#      - Have rollback plan ready

# ===========================================
# PERFORMANCE EXPECTATIONS
# ===========================================

# Expected improvements after optimization:
# - Analytics queries: 30-70% faster execution time
# - Connection establishment: 50% reduction in wait time
# - Database load: 20-40% reduction in CPU usage
# - Query planning: Improved selectivity from indexes
# - Concurrent users: Support 3-5x more concurrent connections

# Monitor these metrics:
# - Average query execution time
# - Connection pool utilization percentage
# - Index hit ratio (should be >95%)
# - Lock wait events (should be minimal)
# - Memory usage patterns

# ===========================================
# TROUBLESHOOTING
# ===========================================

# If connection pool exhaustion occurs:
# 1. Check current connections: SELECT * FROM monitor_connection_pools();
# 2. Identify long-running queries: SELECT * FROM pg_stat_activity WHERE state = 'active';
# 3. Increase pool size or optimize problematic queries

# If index usage is low:
# 1. Check query patterns: EXPLAIN (ANALYZE) your slow queries
# 2. Verify indexes exist: SELECT * FROM analytics_index_usage;
# 3. Update table statistics: ANALYZE scan_events, qr_codes;

# If memory issues occur:
# 1. Reduce work_mem if queries are being spilled to disk
# 2. Monitor shared_buffers usage
# 3. Consider reducing connection pool sizes

# ===========================================
# ROLLBACK INSTRUCTIONS
# ===========================================

# To rollback optimizations if issues occur:
# 1. Restore connection pool settings to original values
# 2. Drop indexes if they cause issues: DROP INDEX CONCURRENTLY index_name;
# 3. Restore from backup created during migration
# 4. Restart services with original configuration

# Original connection pool settings:
# DB_POOL_MAX=20
# DB_POOL_MIN=2  
# DB_IDLE_TIMEOUT=30000
# DB_CONNECTION_TIMEOUT=10000